{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff9d890a-7a73-4be0-92be-c47d148869b6",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "The original dataset was created from imagery over Thailand. Time was ignored, instead observations were averaged together over individual seasons. Here I re-purpose the data to experiment with fitting a 2 dimensional Gaussian. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdb76eb8-07d7-4d30-9c30-38bbd0a10e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import os\n",
    "import censoring\n",
    "\n",
    "RANDOM_SEED = 100\n",
    "np.random.seed(RANDOM_SEED)\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698600c2-a5f1-4f7a-8f06-e031e0c597b6",
   "metadata": {},
   "source": [
    "## Data Loading and Processing\n",
    "It's necessary to merge the Sentinel 1 and Sentinel 2 data together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae2d0fb5-6387-412f-bbe4-5c67d210df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the files\n",
    "def load_files(dir_list): \n",
    "    # use directory to gain list of files\n",
    "    file_list = os.listdir(dir_list)\n",
    "    # set iterator\n",
    "    c = 0\n",
    "    # loop through files\n",
    "    for x in file_list: \n",
    "        temp_df = pd.read_csv(dir_list + '\\\\' + x)\n",
    "        if c == 0: \n",
    "            final_df = temp_df.copy()\n",
    "        else: \n",
    "            final_df = pd.concat([final_df, temp_df], axis=0)\n",
    "        c += 1\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# function to average the observations and merge sentinel1, sentinel2 data\n",
    "def merge_dfs(s1,s2, sub_flag=\"no\"):\n",
    "    # drop the time column\n",
    "    s1 = s1.drop('time', axis=1)\n",
    "    s2 = s2.drop('time', axis=1)\n",
    "    # these are training files\n",
    "    if sub_flag == \"no\":\n",
    "        # average the times together\n",
    "        s1_agg = s1.groupby(['lat','lon','class']).mean().reset_index()\n",
    "        s2_agg = s2.groupby(['lat','lon','class']).mean().reset_index()\n",
    "        # merge\n",
    "        s_final = s1_agg.merge(s2_agg, how=\"inner\", on=['lat','lon','class'])\n",
    "    # these are submission files\n",
    "    else:\n",
    "        # average the times together\n",
    "        s1_agg = s1.groupby(['lat','lon']).mean().reset_index()\n",
    "        s2_agg = s2.groupby(['lat','lon']).mean().reset_index()\n",
    "        # merge\n",
    "        s_final = s1_agg.merge(s2_agg, how=\"inner\", on=['lat','lon'])\n",
    "    \n",
    "    return s_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a438f7-5001-4dc1-af05-42fe54b06bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1_data = load_files(censoring.s1_input)\n",
    "sent2_data = load_files(censoring.s2_input)\n",
    "\n",
    "final_train = merge_dfs(s1=sent1_data, \n",
    "                        s2=sent2_data, \n",
    "                        sub_flag = \"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "739bda1e-5bb1-4ba8-91fc-f86f67849dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>class</th>\n",
       "      <th>vh</th>\n",
       "      <th>vv</th>\n",
       "      <th>rvi</th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "      <th>blue</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>osavi</th>\n",
       "      <th>rdvi</th>\n",
       "      <th>mtvi1</th>\n",
       "      <th>evi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.944900</td>\n",
       "      <td>105.521447</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.024088</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.676813</td>\n",
       "      <td>1918.878094</td>\n",
       "      <td>1689.619048</td>\n",
       "      <td>1804.969548</td>\n",
       "      <td>0.510594</td>\n",
       "      <td>0.510574</td>\n",
       "      <td>33.511181</td>\n",
       "      <td>3598.597527</td>\n",
       "      <td>2.207659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.946717</td>\n",
       "      <td>105.524172</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>0.147283</td>\n",
       "      <td>0.698786</td>\n",
       "      <td>1568.410049</td>\n",
       "      <td>1339.704368</td>\n",
       "      <td>1426.481497</td>\n",
       "      <td>0.524069</td>\n",
       "      <td>0.524048</td>\n",
       "      <td>34.468099</td>\n",
       "      <td>3698.401132</td>\n",
       "      <td>1.320317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.947171</td>\n",
       "      <td>105.517358</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.025577</td>\n",
       "      <td>0.132543</td>\n",
       "      <td>0.651600</td>\n",
       "      <td>1582.573002</td>\n",
       "      <td>1362.996035</td>\n",
       "      <td>1475.847617</td>\n",
       "      <td>0.485330</td>\n",
       "      <td>0.485309</td>\n",
       "      <td>30.715177</td>\n",
       "      <td>3198.024878</td>\n",
       "      <td>2.215421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.948080</td>\n",
       "      <td>105.517358</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.023488</td>\n",
       "      <td>0.123932</td>\n",
       "      <td>0.676208</td>\n",
       "      <td>1574.642861</td>\n",
       "      <td>1335.136503</td>\n",
       "      <td>1442.862699</td>\n",
       "      <td>0.512604</td>\n",
       "      <td>0.512584</td>\n",
       "      <td>33.979766</td>\n",
       "      <td>3667.604974</td>\n",
       "      <td>1.843528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.949897</td>\n",
       "      <td>105.518267</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.025920</td>\n",
       "      <td>0.127763</td>\n",
       "      <td>0.708171</td>\n",
       "      <td>1872.249544</td>\n",
       "      <td>1633.313349</td>\n",
       "      <td>1771.783806</td>\n",
       "      <td>0.495758</td>\n",
       "      <td>0.495739</td>\n",
       "      <td>32.794753</td>\n",
       "      <td>3553.858422</td>\n",
       "      <td>2.248219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat         lon class        vh        vv       rvi        green  \\\n",
       "0  9.944900  105.521447  Rice  0.024088  0.114975  0.676813  1918.878094   \n",
       "1  9.946717  105.524172  Rice  0.030584  0.147283  0.698786  1568.410049   \n",
       "2  9.947171  105.517358  Rice  0.025577  0.132543  0.651600  1582.573002   \n",
       "3  9.948080  105.517358  Rice  0.023488  0.123932  0.676208  1574.642861   \n",
       "4  9.949897  105.518267  Rice  0.025920  0.127763  0.708171  1872.249544   \n",
       "\n",
       "           red         blue      ndvi     osavi       rdvi        mtvi1  \\\n",
       "0  1689.619048  1804.969548  0.510594  0.510574  33.511181  3598.597527   \n",
       "1  1339.704368  1426.481497  0.524069  0.524048  34.468099  3698.401132   \n",
       "2  1362.996035  1475.847617  0.485330  0.485309  30.715177  3198.024878   \n",
       "3  1335.136503  1442.862699  0.512604  0.512584  33.979766  3667.604974   \n",
       "4  1633.313349  1771.783806  0.495758  0.495739  32.794753  3553.858422   \n",
       "\n",
       "        evi  \n",
       "0  2.207659  \n",
       "1  1.320317  \n",
       "2  2.215421  \n",
       "3  1.843528  \n",
       "4  2.248219  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb875be6-41ea-4042-8a36-41ede918072c",
   "metadata": {},
   "source": [
    "## Helpful References Here\n",
    "https://www.pymc-labs.io/blog-posts/spatial-gaussian-process-01/\n",
    "\n",
    "This post describes making a custom class to measure the chordal distance between points of longitude/latitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f61a3f-64d7-495c-931a-b1a75de70a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9849b039-ef44-4ba1-82c9-f61f9af143f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "pymc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
